<configuration debug="false">
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/application-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
        <filter class="ch.qos.logback.core.filter.EvaluatorFilter">
            <evaluator class="ch.qos.logback.classic.boolex.OnMarkerEvaluator">
                <marker>markedMsg</marker>
            </evaluator>
            <onMismatch>NEUTRAL</onMismatch>
            <onMatch>DENY</onMatch>
        </filter>
    </appender>

    <appender name="FILE_MARKER" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${application.home:-.}/logs/markedLog.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>${application.home:-.}/logs/markedLog-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_FILE_MARKER" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="FILE_MARKER" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
        <filter class="ch.qos.logback.core.filter.EvaluatorFilter">
            <evaluator class="ch.qos.logback.classic.boolex.OnMarkerEvaluator">
                <marker>markedMsg</marker>
            </evaluator>
            <onMismatch>DENY</onMismatch>
            <onMatch>NEUTRAL</onMatch>
        </filter>
    </appender>

    <appender name="IMP_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/imp-application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/imp-application-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_IMP_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="IMP_FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="INDEXER_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/indexer-application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/indexer-application-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_INDEXER_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="INDEXER_FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="ES_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/es.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/es-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_ES_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="ES_FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="AKKA_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/akka.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/akka-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} [%thread %X{sourceThread}] %-5level %logger{36} %X{sourceActorSystem} %X{akkaSource} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_AKKA_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="AKKA_FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="RED_LOG" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/red.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/red-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_RED_LOG" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="RED_LOG" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="HEARTBEAT_LOG" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/heartbeat.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/heartbeat-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_HEARTBEAT_LOG" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="HEARTBEAT_LOG" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="CRAWLER_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/crawler.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/crawler-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_CRAWLER__FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="CRAWLER_FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <logger name="cmwell.bg.ImpStream" additivity="false">
        <appender-ref ref="ASYNC_IMP_FILE"/>
    </logger>

    <logger name="cmwell.bg.IndexerStream" additivity="false">
        <appender-ref ref="ASYNC_INDEXER_FILE"/>
    </logger>

    <logger name="bg_red_log" additivity="false">
        <appender-ref ref="ASYNC_RED_LOG" />
    </logger>

    <logger name="heartbeat_log" additivity="false">
        <appender-ref ref="ASYNC_HEARTBEAT_LOG" />
    </logger>

    <logger name="org.elasticsearch" additivity="false">
        <appender-ref ref="ASYNC_ES_FILE"/>
    </logger>

    <logger name="akka" additivity="true">
        <appender-ref ref="ASYNC_AKKA_FILE" />
    </logger>

    <logger name="cmwell.fts.FTSServiceNew" additivity="true">
        <appender-ref ref="ASYNC_FILE_MARKER" />
    </logger>

    <logger name="cmwell.crawler" additivity="false">
        <appender-ref ref="ASYNC_CRAWLER__FILE"/>
    </logger>

    <root level="${log.level:-INFO}">
        <appender-ref ref="ASYNC_FILE" />
    </root>
    <jmxConfigurator />
</configuration>
