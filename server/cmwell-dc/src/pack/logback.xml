<configuration debug="false">
    <!--
    A shutdown hook to properly finalize the logger system.
    In order to avoid race conditions between shutdown hooks (logs from another one won't be printed) there is
    a delay of 5 seconds that allows other hooks to write logs.
    This will cause the process shutdown to be delayed with 5 seconds.
    -->
    <shutdownHook class="ch.qos.logback.core.hook.DelayingShutdownHook">
        <delay>5000</delay>
    </shutdownHook>

    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/application-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- this quadruples logging throughput -->
        <immediateFlush>false</immediateFlush>
    </appender>

    <appender name="ASYNC_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="AKKA_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/akka.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/akka-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} [%thread %X{sourceThread}] %-5level %logger{36} %X{sourceActorSystem} %X{akkaSource} - %msg%n</pattern>
        </encoder>
        <!-- this quadruples logging throughput -->
        <immediateFlush>false</immediateFlush>
    </appender>

    <appender name="ASYNC_AKKA_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="AKKA_FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="RED_LOG" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/red.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/red-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- this quadruples logging throughput -->
        <immediateFlush>false</immediateFlush>
    </appender>

    <appender name="ASYNC_RED_LOG" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="RED_LOG" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="YELLOW_LOG" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/yellow.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/yellow-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- this quadruples logging throughput -->
        <immediateFlush>false</immediateFlush>
    </appender>

    <appender name="ASYNC_YELLOW_LOG" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="YELLOW_LOG" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="CLUSTER_STATE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/cluster_state.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/cluster_state-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- this quadruples logging throughput -->
        <immediateFlush>false</immediateFlush>
    </appender>

    <!--Alerts log is used by the devOps team to monitor the cluster state, hence the special message pattern-->
    <appender name="ALERTS" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/alerts.log</file>
        <append>true</append>
        <encoder>
            <pattern>%msg%n</pattern>
        </encoder>

        <rollingPolicy class="ch.qos.logback.core.rolling.FixedWindowRollingPolicy">
            <fileNamePattern>logs/alerts.log.%i</fileNamePattern>
            <maxIndex>21</maxIndex>
        </rollingPolicy>
        <triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy">
            <maxFileSize>10000000</maxFileSize>
        </triggeringPolicy>
    </appender>

    <appender name="AGENTS_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/agents.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/agents-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- this quadruples logging throughput -->
        <immediateFlush>false</immediateFlush>
    </appender>

    <appender name="ASYNC_AGENTS_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="AGENTS_FILE" />
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <logger name="alerts" additivity="false">
        <appender-ref ref="ALERTS" />
    </logger>

    <logger name="cluster_state" additivity="false">
        <appender-ref ref="CLUSTER_STATE" />
    </logger>

    <logger name="dc_red_log" additivity="false">
        <appender-ref ref="ASYNC_RED_LOG" />
    </logger>

    <logger name="dc_yellow_log" additivity="false">
        <appender-ref ref="ASYNC_YELLOW_LOG" />
    </logger>

    <logger name="akka" additivity="true">
        <appender-ref ref="ASYNC_AKKA_FILE" />
    </logger>

    <logger name="cmwell.tools.data.sparql" additivity="false">
        <appender-ref ref="ASYNC_AGENTS_FILE"/>
    </logger>

    <root level="${log.level:-INFO}">
        <appender-ref ref="ASYNC_FILE" />
    </root>
    <jmxConfigurator />
</configuration>
