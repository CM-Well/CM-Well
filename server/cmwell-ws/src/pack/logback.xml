<configuration debug="false">
    <!--
    A shutdown hook to properly finalize the logger system.
    In order to avoid race conditions between shutdown hooks (logs from another one won't be printed) there is
    a delay of 5 seconds that allows other hooks to write logs.
    This will cause the process shutdown to be delayed with 5 seconds.
    -->
    <shutdownHook class="ch.qos.logback.core.hook.DelayingShutdownHook">
        <delay>5000</delay>
    </shutdownHook>

    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${application.home:-.}/logs/application.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>${application.home:-.}/logs/application-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
        <filter class="ch.qos.logback.core.filter.EvaluatorFilter">
            <evaluator class="ch.qos.logback.classic.boolex.OnMarkerEvaluator">
                <marker>markedMsg</marker>
            </evaluator>
            <onMismatch>NEUTRAL</onMismatch>
            <onMatch>DENY</onMatch>
        </filter>
    </appender>

    <appender name="FILE_MARKER" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${application.home:-.}/logs/markedLog.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>${application.home:-.}/logs/markedLog-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_FILE_MARKER" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="FILE_MARKER" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
        <filter class="ch.qos.logback.core.filter.EvaluatorFilter">
            <evaluator class="ch.qos.logback.classic.boolex.OnMarkerEvaluator">
                <marker>markedMsg</marker>
            </evaluator>
            <onMismatch>DENY</onMismatch>
            <onMatch>NEUTRAL</onMatch>
        </filter>
    </appender>

    <appender name="AKKA_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>logs/akka.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>logs/akka-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} [%thread %X{sourceThread}] %-5level %logger{36} %X{sourceActorSystem} %X{akkaSource} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_AKKA_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="AKKA_FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="ACCESS_FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${application.home:-.}/logs/access.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>${application.home:-.}/logs/access-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_ACCESS_FILE" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="ACCESS_FILE" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="X_FIX" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${application.home:-.}/logs/x-fix.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>${application.home:-.}/logs/x-fix-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_X_FIX" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="X_FIX" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <appender name="BAD_INGESTS" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${application.home:-.}/logs/bad-ingests.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
            <!-- daily rollover with compression -->
            <fileNamePattern>${application.home:-.}/logs/bad-ingests-log-%d{yyyy-MM-dd, UTC}.%i.gz</fileNamePattern>
            <!-- keep 1 week worth of history (max 20GB) with each file compressed after 100MB -->
            <maxFileSize>100MB</maxFileSize>
            <maxHistory>7</maxHistory>
            <totalSizeCap>20GB</totalSizeCap>
            <!-- in case of process terminating too early for rollover - do the rollover during start -->
            <cleanHistoryOnStart>true</cleanHistoryOnStart>
        </rollingPolicy>
        <encoder>
            <pattern>%date{ISO8601} %-44.44([%thread]) %-5level %-36.36logger{36} - %msg%n</pattern>
        </encoder>
        <!-- false quadruples logging throughput -->
        <immediateFlush>true</immediateFlush>
    </appender>

    <appender name="ASYNC_BAD_INGESTS" class="ch.qos.logback.classic.AsyncAppender">
        <appender-ref ref="BAD_INGESTS" />
        <maxFlushTime>0</maxFlushTime>
        <discardingThreshold>0</discardingThreshold>
    </appender>

    <!--X-fix is a special operation that should always be logged. CM-Well root logger level can
    dynamically be changed. Setting the x-fix level to info fixes it to info always-->
    <logger name="cmwell.xfix" level="INFO" additivity="false">
        <appender-ref ref="ASYNC_X_FIX"/>
    </logger>

    <logger name="access" additivity="false">
        <appender-ref ref="ASYNC_ACCESS_FILE" />
    </logger>

    <logger name="cmwell.fts.FTSServiceNew" additivity="true">
        <appender-ref ref="ASYNC_FILE_MARKER" />
    </logger>

    <logger name="akka" additivity="true">
        <appender-ref ref="ASYNC_AKKA_FILE" />
    </logger>

    <logger name="bad_ingests" additivity="false">
        <appender-ref ref="ASYNC_BAD_INGESTS" />
    </logger>

    <root level="${log.level:-INFO}">
        <appender-ref ref="ASYNC_FILE" />
    </root>
    <jmxConfigurator />
</configuration>
